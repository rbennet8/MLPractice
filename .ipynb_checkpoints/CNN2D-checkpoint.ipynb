{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb8dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from numpy import argmax\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00740086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenSeqs():\n",
    "    alphabet = 'GATC'\n",
    "    bindingSeq = 'GGAATTCCTTAAGGAATTCCTTAAGGAATTCCTTAAGG'\n",
    "    withBinding = 1000-len(bindingSeq)\n",
    "    \n",
    "    totalSeqs = pd.DataFrame(columns = ['Names', 'Sequences', 'Labels'])\n",
    "    \n",
    "    for x in range(2500):\n",
    "        crm = []\n",
    "        seq = ''\n",
    "        for i in range(withBinding+1):\n",
    "            if(i == withBinding/2):\n",
    "                seq = seq + bindingSeq\n",
    "            else:\n",
    "                seq = seq + alphabet[random.randint(0, 3)]\n",
    "        crm.append('CRM seq ' + str(x+1))\n",
    "        crm.append(seq)\n",
    "        crm.append(1)\n",
    "        totalSeqs.loc[len(totalSeqs)] = crm\n",
    "    \n",
    "    for x in range(2500):\n",
    "        nonCrm = []\n",
    "        seq = ''\n",
    "        for i in range(1000):\n",
    "            seq = seq + alphabet[random.randint(0, 3)]\n",
    "        nonCrm.append('Non-CRM seq ' + str(x+1))\n",
    "        nonCrm.append(seq)\n",
    "        nonCrm.append(0)\n",
    "        totalSeqs.loc[len(totalSeqs)] = nonCrm\n",
    "    \n",
    "    print(totalSeqs)\n",
    "    \n",
    "    return totalSeqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb83be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHot(data):\n",
    "    num_classes = 4\n",
    "    new_data = []\n",
    "\n",
    "    for x in data:\n",
    "        class_vector = np.array(x)\n",
    "        categorical = np.zeros(class_vector.shape+(num_classes,))\n",
    "        for c in range(1,5,1):\n",
    "            categorical[np.where(class_vector == c)]=np.array([1 if i == c else 0.0 for i in range(1,5,1)])\n",
    "        new_data.append(categorical)\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b5e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Names                                          Sequences  \\\n",
      "0            CRM seq 1  TGGCGCTCATTTTACGTTCTTTAGACTGAGTTTGATTACTGCCTAC...   \n",
      "1            CRM seq 2  CGACTCGCACCGCGATCTGGAGCTGTCGGATCCTGAGGAGCAAGAG...   \n",
      "2            CRM seq 3  GACGATCCGACCGGTCTAGGATAGTCTCTAAGTCAGACAACCGCAT...   \n",
      "3            CRM seq 4  AGACGGCTTGGAAAGAGAGCTATTTCTCGCCTGGACTGCACGGTGA...   \n",
      "4            CRM seq 5  GACGTTACCACCATTGATCCTACTGTGAGGGTTGCATGGAGGATGC...   \n",
      "...                ...                                                ...   \n",
      "4995  Non-CRM seq 2496  GCTTTTAGCTCTGGCGCATAGCAGCCGCTGCCACGCAGAACTTCGT...   \n",
      "4996  Non-CRM seq 2497  GGAATCCTCGATCGAAGTTAGGTGGCCGATCTCTCAGATGTCACCC...   \n",
      "4997  Non-CRM seq 2498  CGCATGTCTTGTATGCAGAAACGCTTATGGATTTAACACGGGCAAG...   \n",
      "4998  Non-CRM seq 2499  GGGTGACGTCTTTGCCATTACAGTTATAATAGTCGTACGATCCGGT...   \n",
      "4999  Non-CRM seq 2500  TATTCACCAAATTTTCTCTTAACTAGGTAACTTACTACTGTAAAAG...   \n",
      "\n",
      "     Labels  \n",
      "0         1  \n",
      "1         1  \n",
      "2         1  \n",
      "3         1  \n",
      "4         1  \n",
      "...     ...  \n",
      "4995      0  \n",
      "4996      0  \n",
      "4997      0  \n",
      "4998      0  \n",
      "4999      0  \n",
      "\n",
      "[5000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Returns Pandas dataframe of names, sequences, and labels\n",
    "totalSeqs = GenSeqs()\n",
    "\n",
    "# Splitting data and labels in to train/validation sets\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(totalSeqs.Sequences.tolist(), totalSeqs.Labels.tolist(), test_size = 0.1)\n",
    "x_tr, x_val, y_tr, y_val = np.array(x_tr), np.array(x_val), np.array(y_tr), np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1552d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing sequences\n",
    "tk = Tokenizer(num_words=None, char_level=True)\n",
    "tk.fit_on_texts(x_tr)\n",
    "tokenTrain = tk.texts_to_sequences(x_tr)\n",
    "tokenValidate = tk.texts_to_sequences(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1472b9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('g', 1122233), ('t', 1130736), ('c', 1116442), ('a', 1130589)])\n",
      "{'t': 1, 'a': 2, 'g': 3, 'c': 4}\n",
      "defaultdict(<class 'int'>, {'g': 4500, 'c': 4500, 't': 4500, 'a': 4500})\n",
      "[3, 1, 3, 1, 4, 4, 4, 3, 4, 2, 4, 4, 3, 4, 3, 4, 3, 1, 2, 3, 2, 1, 4, 4, 3, 1, 1, 1, 1, 1, 3, 3, 3, 4, 1, 2, 2, 2, 4, 2, 3, 3, 1, 4, 4, 3, 2, 1, 3, 4, 1, 2, 1, 3, 3, 2, 3, 3, 4, 3, 3, 1, 4, 2, 1, 2, 3, 3, 2, 2, 3, 1, 3, 3, 2, 2, 4, 3, 1, 3, 4, 2, 1, 4, 4, 1, 2, 1, 4, 3, 2, 3, 3, 2, 3, 1, 2, 1, 1, 4, 2, 2, 1, 4, 2, 2, 3, 4, 2, 1, 1, 4, 2, 1, 1, 2, 1, 4, 2, 1, 4, 3, 1, 2, 4, 1, 3, 3, 2, 2, 4, 4, 4, 4, 1, 3, 4, 1, 1, 1, 1, 3, 2, 3, 1, 3, 2, 3, 4, 2, 3, 4, 1, 2, 1, 1, 4, 2, 3, 3, 3, 1, 4, 2, 2, 2, 2, 2, 1, 4, 3, 2, 3, 3, 2, 4, 4, 3, 1, 2, 2, 3, 1, 4, 1, 2, 1, 4, 3, 2, 2, 1, 1, 2, 3, 4, 1, 3, 2, 1, 1, 3, 4, 1, 4, 4, 4, 4, 3, 1, 2, 1, 3, 3, 4, 1, 2, 4, 2, 4, 4, 3, 3, 1, 3, 3, 4, 2, 2, 1, 3, 2, 3, 4, 1, 2, 1, 1, 1, 4, 4, 3, 3, 2, 2, 4, 3, 4, 2, 3, 3, 4, 4, 3, 3, 4, 4, 2, 3, 4, 2, 1, 3, 3, 1, 4, 3, 1, 1, 3, 1, 4, 1, 4, 2, 2, 1, 3, 2, 1, 3, 2, 3, 2, 4, 1, 2, 3, 3, 1, 4, 4, 4, 4, 4, 4, 2, 3, 1, 4, 4, 1, 2, 3, 1, 1, 2, 1, 3, 2, 1, 4, 1, 4, 4, 2, 3, 1, 4, 1, 1, 3, 1, 4, 2, 4, 2, 4, 1, 1, 4, 1, 1, 4, 3, 4, 4, 3, 4, 3, 2, 2, 2, 3, 3, 2, 1, 4, 4, 4, 1, 3, 1, 1, 2, 4, 1, 3, 4, 2, 1, 4, 2, 4, 2, 3, 1, 1, 4, 4, 1, 2, 3, 4, 4, 4, 3, 2, 1, 3, 2, 2, 1, 3, 2, 4, 2, 4, 4, 4, 3, 4, 1, 2, 3, 4, 4, 2, 1, 1, 2, 2, 2, 3, 2, 4, 2, 1, 2, 3, 3, 3, 2, 1, 3, 4, 4, 1, 4, 4, 2, 3, 3, 4, 4, 1, 1, 1, 3, 1, 2, 4, 2, 4, 1, 2, 3, 1, 2, 1, 2, 3, 3, 1, 1, 1, 4, 2, 3, 2, 1, 4, 4, 2, 2, 3, 3, 1, 2, 2, 2, 3, 4, 1, 4, 2, 3, 3, 1, 1, 3, 4, 3, 1, 2, 3, 4, 1, 4, 4, 2, 3, 3, 2, 2, 1, 1, 4, 4, 1, 1, 2, 2, 3, 3, 2, 2, 1, 1, 4, 4, 1, 1, 2, 2, 3, 3, 2, 2, 1, 1, 4, 4, 1, 1, 2, 2, 3, 3, 3, 3, 2, 1, 4, 3, 2, 4, 4, 4, 4, 4, 1, 2, 3, 1, 1, 3, 3, 2, 4, 3, 1, 3, 2, 1, 2, 4, 1, 4, 2, 2, 4, 4, 2, 3, 2, 1, 3, 2, 2, 3, 4, 1, 1, 3, 1, 3, 1, 4, 2, 4, 3, 2, 1, 3, 1, 1, 2, 4, 4, 1, 4, 3, 4, 3, 3, 2, 1, 3, 3, 1, 3, 1, 2, 2, 4, 1, 1, 4, 3, 3, 4, 4, 2, 3, 3, 3, 2, 2, 3, 4, 3, 2, 2, 1, 1, 4, 2, 1, 1, 2, 2, 4, 2, 1, 4, 1, 2, 1, 1, 2, 3, 1, 4, 3, 1, 2, 4, 3, 2, 4, 2, 2, 4, 1, 1, 3, 3, 4, 4, 4, 4, 3, 2, 3, 4, 2, 2, 4, 2, 2, 2, 3, 3, 2, 1, 2, 4, 4, 2, 1, 1, 2, 4, 3, 2, 2, 3, 1, 4, 1, 4, 1, 3, 4, 2, 1, 1, 3, 1, 2, 1, 4, 2, 2, 1, 4, 1, 3, 3, 1, 3, 2, 4, 2, 3, 1, 2, 2, 4, 3, 4, 4, 3, 2, 2, 4, 1, 4, 2, 3, 3, 4, 1, 1, 3, 1, 3, 1, 4, 2, 2, 2, 1, 1, 4, 4, 3, 1, 3, 1, 4, 4, 4, 4, 3, 2, 3, 4, 3, 4, 2, 2, 1, 4, 3, 2, 3, 1, 4, 4, 2, 2, 1, 1, 4, 1, 3, 4, 1, 4, 2, 2, 3, 4, 3, 2, 2, 3, 2, 2, 2, 4, 2, 1, 4, 4, 4, 4, 1, 3, 4, 2, 4, 4, 4, 3, 4, 2, 3, 2, 4, 4, 2, 4, 1, 2, 3, 2, 4, 4, 2, 1, 2, 1, 3, 1, 1, 4, 1, 3, 2, 4, 3, 1, 1, 2, 3, 2, 2, 1, 1, 2, 2, 1, 1, 4, 1, 3, 2, 2, 3, 1, 2, 4, 2, 4, 3, 4, 3, 4, 3, 3, 4, 3, 2, 1, 1, 2, 4, 3, 2, 1, 3, 4, 3, 2, 4, 2, 3, 3, 3, 2, 2, 1, 4, 2, 4, 4, 1, 2, 4, 1, 2, 1, 4, 4, 2, 4, 2, 1, 3, 2, 3, 4, 2, 4, 2, 1, 1, 3, 3, 4, 1, 2, 2, 3, 1, 1, 4, 1, 1, 4, 1, 4, 3, 1, 4, 3, 3, 2, 4, 2, 2, 4, 3, 3, 3, 1, 4, 4, 1, 3, 4, 3, 3, 2, 1, 2, 2, 1, 3, 3, 1, 4, 1, 3, 3, 3, 4, 2, 3, 1, 4, 1, 3, 4, 1, 3, 3, 4, 2, 2, 4, 2, 1, 2, 1, 2, 4, 1, 2, 1, 1, 1, 3, 4, 3, 4, 1, 4, 3, 1, 1, 1, 4, 4, 3, 2, 1, 1, 3, 2, 3, 3, 2, 2, 4, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "print(tk.word_counts)\n",
    "print(tk.word_index)\n",
    "print(tk.word_docs)\n",
    "print(tokenTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9410783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Onehot encoding tokenized sequences\n",
    "oneHotTrain = OneHot(tokenTrain)\n",
    "oneHotValidate = OneHot(tokenValidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0bf14b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 1000, 4, 1)\n",
      "(500, 1000, 4, 1)\n",
      "(4500, 1)\n",
      "(500, 1)\n"
     ]
    }
   ],
   "source": [
    "# Resizing to fit Conv2D and making sure there aren't any array/list conflicts\n",
    "oneHotTrain = np.array(oneHotTrain).reshape(4500, 1000, 4, 1).astype('float32')\n",
    "print(oneHotTrain.shape)\n",
    "oneHotValidate = np.array(oneHotValidate).reshape(500, 1000, 4, 1).astype('float32')\n",
    "print(oneHotValidate.shape)\n",
    "\n",
    "trainLabels = y_tr.reshape(4500, 1)\n",
    "print(trainLabels.shape)\n",
    "validateLabels = y_val.reshape(500, 1)\n",
    "print(validateLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fcb4c84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING:\n",
      "Epoch 1/5\n",
      "45/45 [==============================] - 15s 323ms/step - loss: 0.4121 - accuracy: 0.8469\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 15s 330ms/step - loss: 9.7011e-04 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 15s 327ms/step - loss: 1.7721e-04 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 14s 322ms/step - loss: 1.4155e-04 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 14s 312ms/step - loss: 1.1366e-04 - accuracy: 1.0000\n",
      "VALIDATION:\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.7803e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (4,1), activation = 'relu', input_shape = (1000, 4, 1)))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "model.add(Conv2D(64, 4, activation = 'relu'))\n",
    "model.add(MaxPooling2D(1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#optimizer = keras.optimizers.Adam(lr = 0.000001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"TRAINING:\")\n",
    "final = model.fit(oneHotTrain, trainLabels, batch_size = 100, epochs = 5, verbose = 1)\n",
    "    \n",
    "print(\"VALIDATION:\")\n",
    "validate = model.evaluate(oneHotValidate, validateLabels, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562eef04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
